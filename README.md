
## Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis
Code for the paper [Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis](https://www.aclweb.org/anthology/N19-1034/) (NAACL 2019)

For the evaluation of our proposed multi-task CIM framerwork, we use benchmark multi-modal dataset i.e, MOSEI which has both sentiment and emotion classes.

### Dataset

* You can download datasets from [here](https://drive.google.com/open?id=1kq4_WqW0tDzBLu01yZbvdCpQ0iPBJWyQ).

* Download the dataset from given link and set the path in the code accordingly make two folders (i) results and (ii) weights.

-------------------------------------------------------
### For MOSEI Dataset:
For trimodal-->>  python trimodal_multitask.py  
